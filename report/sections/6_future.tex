% !TEX root=../report.tex

\section{Conclusion}
\label{sec:conclusion}

While the results from our DQN network are quite impressive (which was not expected), DDPG and MADDPG are larger networks (especially MADDPG which takes the states and actions of all agents into account) and most likely require more hyperparameter tuning and longer training times. They should not just be competitive, but better at formulating cooperative and competitive strategies than DQN agents in multi-agent scenarios.

Furthermore, TODO 

