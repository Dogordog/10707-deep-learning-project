% !TEX root=../report.tex

\section{Environment and Applications}
\label{sec:application}

In this project, we use the OpenAI Gym framework~\cite{gym.openai16}, which
generates virtually infinite amount of data for training and testing our
neural network. This framework includes various gym environments that simulate
various reinforcement learning settings. Each gym environment defines the
\emph{state space} (i.e., all possible states of the environment) and the
action space (i.e., all possible actions of the agent). Note that a gym
environment is turn-based, i.e., the agent can only take one action per time
step to influence the state at the next time step. In each time step, the
environment computes the next state and the immediate reward for each agent,
and decide if the episode is finished or not. These pieces of information
(i.e., the immediate reward and the episode finished signal) are used by each
agent to decide the best action in the next step. We refer the readers to
Section~\ref{sec:background:problem} for a detailed explanation of a classical
reinforcement learning problem setting.

\subsection{The Predator-Pray Environment}

We develop a modified version of the \emph{``predator-pray''} gym environment
in the ``multi-agent particle'' environment suite developed by prior
work~\cite{lowe2017multi, mordatch2017emergence}, and train our
neural-network-based agents. In the original classic predator-prey game, $N$
slower cooperating agents must chase the faster adversary around a randomly
generated environment with $L$ large landmarks impeding the way. Each time the
cooperative agents collide with an adversary, the agents are rewarded while
the adversary is penalized. Agents observe the relative positions and
velocities of the agents, and the positions of the landmarks. We introduce the
state space, action space, the reward function, and our modifications to the
environment.

\paragraph{State Space.} In predator-pray environment, the state space is a
list of the observable state of each agent ($state[i]$).



